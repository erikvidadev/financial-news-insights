{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-title",
   "metadata": {},
   "source": [
    "# Data Cleaning - News and Sentiment Analysis\n",
    "\n",
    "This notebook performs data cleaning operations on news articles with sentiment scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-section",
   "metadata": {},
   "source": [
    "## 1. Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-section",
   "metadata": {},
   "source": [
    "## 2. Load CSV Data\n",
    "\n",
    "**Note:** Update the file path below to match your data location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/processed/articles_with_sentiment_score.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "select-columns-section",
   "metadata": {},
   "source": [
    "## 3. Select Required Columns and Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "select-rename-columns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns selected and renamed:\n",
      "['Date', 'Title', 'Content', 'Sentiment Score']\n"
     ]
    }
   ],
   "source": [
    "columns_needed = [\"publishedAt\", \"title\", \"full_text\", \"sentiment\"]\n",
    "df_cleaned = df[columns_needed].copy()\n",
    "\n",
    "df_cleaned = df_cleaned.rename(columns={\n",
    "    \"publishedAt\": \"Date\",\n",
    "    \"title\": \"Title\",\n",
    "    \"full_text\": \"Content\",\n",
    "    \"sentiment\": \"Sentiment Score\"\n",
    "})\n",
    "\n",
    "print(\"Columns selected and renamed:\")\n",
    "print(df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-values-section",
   "metadata": {},
   "source": [
    "## 4. Check and Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "check-missing-values",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count by column:\n",
      "Date               0\n",
      "Title              0\n",
      "Content            0\n",
      "Sentiment Score    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values percentage:\n",
      "Date               0.0\n",
      "Title              0.0\n",
      "Content            0.0\n",
      "Sentiment Score    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values count by column:\")\n",
    "missing_counts = df_cleaned.isnull().sum()\n",
    "print(missing_counts)\n",
    "\n",
    "print(\"\\nMissing values percentage:\")\n",
    "missing_percentage = (df_cleaned.isnull().sum() / len(df_cleaned)) * 100\n",
    "print(missing_percentage.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "handle-missing-values",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning: 86\n",
      "Rows after cleaning: 86\n",
      "Rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "rows_before = len(df_cleaned)\n",
    "df_cleaned.dropna(inplace=True)\n",
    "rows_after = len(df_cleaned)\n",
    "\n",
    "print(f\"Rows before cleaning: {rows_before}\")\n",
    "print(f\"Rows after cleaning: {rows_after}\")\n",
    "print(f\"Rows removed: {rows_before - rows_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "date-processing-section",
   "metadata": {},
   "source": [
    "## 5. Process and Format Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "process-dates",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"Date\"] = pd.to_datetime(df_cleaned[\"Date\"]).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remove-duplicates-section",
   "metadata": {},
   "source": [
    "## 6. Remove Duplicate Records Based on Date and Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "check-duplicates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicate records based on Date and Title...\n",
      "Total rows before duplicate removal: 86\n",
      "Number of duplicate rows found: 0\n",
      "Unique duplicate pairs: 0\n",
      "No duplicates found.\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for duplicate records based on Date and Title...\")\n",
    "print(f\"Total rows before duplicate removal: {len(df_cleaned)}\")\n",
    "\n",
    "# Megkeressük a duplikált sorokat\n",
    "duplicates = df_cleaned[df_cleaned.duplicated(subset=['Date', 'Title'], keep=False)]\n",
    "duplicate_count = len(duplicates)\n",
    "\n",
    "print(f\"Number of duplicate rows found: {duplicate_count}\")\n",
    "print(f\"Unique duplicate pairs: {duplicate_count // 2 if duplicate_count > 0 else 0}\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(\"\\nDuplicate records (showing first 10):\")\n",
    "    print(\"=\" * 60)\n",
    "    display(duplicates[['Date', 'Title', 'Sentiment Score']].head(10))\n",
    "\n",
    "    # Megmutatjuk a legtöbb duplikált sort tartalmazó dátumokat\n",
    "    duplicate_dates = duplicates['Date'].value_counts().head(5)\n",
    "    print(\"\\nTop 5 dates with most duplicates:\")\n",
    "    print(duplicate_dates)\n",
    "\n",
    "    # Ténylegesen eltávolítjuk a duplikált sorokat\n",
    "    df_cleaned = df_cleaned.drop_duplicates(subset=['Date', 'Title'])\n",
    "    print(f\"\\nDuplicates removed. Total rows after removal: {len(df_cleaned)}\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "remove-duplicates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before duplicate removal: 86\n",
      "Rows after duplicate removal: 86\n",
      "Duplicate rows removed: 0\n",
      "Duplicate removal rate: 0.0%\n",
      "\n",
      "DataFrame index has been reset.\n",
      "Final dataset size: 86 rows\n",
      "Verification: 0 duplicates remaining (should be 0)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates - keep the first occurrence\n",
    "rows_before_dedup = len(df_cleaned)\n",
    "df_cleaned = df_cleaned.drop_duplicates(subset=['Date', 'Title'], keep='first')\n",
    "rows_after_dedup = len(df_cleaned)\n",
    "duplicates_removed = rows_before_dedup - rows_after_dedup\n",
    "\n",
    "print(f\"Rows before duplicate removal: {rows_before_dedup}\")\n",
    "print(f\"Rows after duplicate removal: {rows_after_dedup}\")\n",
    "print(f\"Duplicate rows removed: {duplicates_removed}\")\n",
    "print(f\"Duplicate removal rate: {(duplicates_removed/rows_before_dedup*100):.1f}%\")\n",
    "\n",
    "# Reset index after removing duplicates\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "print(f\"\\nDataFrame index has been reset.\")\n",
    "print(f\"Final dataset size: {len(df_cleaned)} rows\")\n",
    "\n",
    "# Verify no duplicates remain\n",
    "remaining_duplicates = df_cleaned.duplicated(subset=['Date', 'Title']).sum()\n",
    "print(f\"Verification: {remaining_duplicates} duplicates remaining (should be 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-data-section",
   "metadata": {},
   "source": [
    "## 7. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "save-cleaned-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: ../data/cleaned/cleaned_news_data.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../data/cleaned/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save cleaned data to CSV\n",
    "cleaned_file_path = os.path.join(output_dir, \"cleaned_news_data.csv\")\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to: {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-section",
   "metadata": {},
   "source": [
    "## 8. Display Results and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "display-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of cleaned data:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>Apple has a new ‘Viral’ playlist on Apple Musi...</td>\n",
       "      <td>Apple is launching a new global Viral Chart pl...</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>Spotify already has an app ready to test Apple...</td>\n",
       "      <td>Spotify says it has submitted an update to its...</td>\n",
       "      <td>0.9761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-13</td>\n",
       "      <td>How to Use Apple Maps on the Web</td>\n",
       "      <td>The boundaries of Apple’s walled garden aren’t...</td>\n",
       "      <td>0.9715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>Trump’s Tariffs Are Threatening America’s Appl...</td>\n",
       "      <td>Few foods are more American than apple pie, bu...</td>\n",
       "      <td>0.9901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>How Apple lost control of the App Store</td>\n",
       "      <td>“Cook chose poorly” is one of those phrases yo...</td>\n",
       "      <td>0.9613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Title  \\\n",
       "0  2025-05-08  Apple has a new ‘Viral’ playlist on Apple Musi...   \n",
       "1  2025-05-01  Spotify already has an app ready to test Apple...   \n",
       "2  2025-05-13                   How to Use Apple Maps on the Web   \n",
       "3  2025-05-06  Trump’s Tariffs Are Threatening America’s Appl...   \n",
       "4  2025-05-02            How Apple lost control of the App Store   \n",
       "\n",
       "                                             Content  Sentiment Score  \n",
       "0  Apple is launching a new global Viral Chart pl...           0.7650  \n",
       "1  Spotify says it has submitted an update to its...           0.9761  \n",
       "2  The boundaries of Apple’s walled garden aren’t...           0.9715  \n",
       "3  Few foods are more American than apple pie, bu...           0.9901  \n",
       "4  “Cook chose poorly” is one of those phrases yo...           0.9613  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"First 5 rows of cleaned data:\")\n",
    "print(\"=\" * 50)\n",
    "display(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-info",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
